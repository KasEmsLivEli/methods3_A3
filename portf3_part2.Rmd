---
title: "Portfolio 3, part 2"
author: "Elisabet, Kasper, Emma-Louise og Liv"
date: "28/10/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}

#loading data and packages
df <- read_csv("scaled_data.csv")
pacman::p_load(groupdata2, cvms, dplyr, tidyverse, lmerTest, caret, kernlab, recipes, parsnip, lme4, tidymodels)

#Grouping each variable by participant to achieve a single datapoint (instead of 8)
grouped_iqr <- aggregate(x = df$Iqr, by = list(df$uID), FUN = mean, na.rm=T) %>% dplyr::rename(iqr=x)
grouped_sd <- aggregate(x = df$Sd, by = list(df$uID), FUN = mean, na.rm=T) %>% dplyr::rename(sd=x)
grouped_pauseDuration <- aggregate(x = df$pauseduration, by = list(df$uID), FUN = mean, na.rm=T) %>% dplyr::rename(pauseduration=x)
grouped_propSpokenTime <- aggregate(x = df$propspoken, by = list(df$uID), FUN = mean, na.rm=T) %>% dplyr::rename(propspoken=x)
grouped_speechrate <- aggregate(x = df$Art_rate_syl_speechpresent, by = list(df$uID), FUN = mean, na.rm=T) %>% dplyr::rename(speechrate=x)
grouped_diagnosis <- aggregate(x = as.numeric(df$Diagnosis), by = list(df$uID), FUN = mean, na.rm=T) %>% dplyr::rename(diagnosis=x)
write_csv(groupedData, "groupedData.csv")

```



```{r}
df <- read_csv("groupedData.csv")
##feature preprocessing:
#partioning using package groupdata2. data is subset into two by cat_cols
df_list <- partition(df, p = 0.2, cat_col = c("diagnosis",'study'), list_out = T)

#defining test set and removing ID and study column, so they aren't scaled
df_test <- df_list[[1]]
df_test <- df_test %>% 
  select(-ID, -study)

#defining train set and removing ID and study column, so they aren't scaled
df_train <- df_list[[2]]
df_train <- df_train %>% 
  select(-ID, -study)


#defining the recipe for train-data
#the na's are removed so no need to check for missing values
rec <- df_train %>% recipe(diagnosis ~ .) %>% # defines outcome of pre-processing
  step_center(all_numeric()) %>% # centering all numeric values
  step_scale(all_numeric()) %>% # scaling all numeric values
  step_corr(all_numeric()) %>% # corr testing all predictors
  prep(training = df_train) # defining the train-set

#extracting finalized (with applied operations) 'df_train' from rec (the recipe)
train_juiced <- juice(rec) #juice is essentially scaling by mean and sd of train data
test_baked <- rec %>% bake(df_test) #bake function is using the scaling from the ''juiced'' trained data

```


```{r}
##model training step 0
#sidestep, diagnosis (the outcome) has to be a factor for classification step below
train_juiced$diagnosis <- as.factor(train_juiced$diagnosis)
test_baked$diagnosis <- as.factor(test_baked$diagnosis)

#defining model for log reg and SVM
log_fit <- 
  logistic_reg() %>% 
  set_mode("classification") %>% 
  set_engine("glm") %>% 
  fit(diagnosis ~ ., data = train_juiced)

svm_fit <- 
  svm_rbf() %>% 
  set_mode("classification") %>% 
  set_engine("kernlab") %>%
  fit(diagnosis ~ ., data = train_juiced)

#investigating model/model assessment: slide 11 in the part two powerpoint
test_results <-
  df_test %>%
  as_tibble() %>% 
  mutate(
    log_class = predict(log_fit, new_data = test_baked) %>% 
      pull (.pred_class),
    log_prob = predict(log_fit, new_data = test_baked, type = "prob") %>% 
      pull (.pred_1.01605975626787),
    
    svm_class = predict(svm_fit, new_data = test_baked) %>% 
      pull (.pred_class),
    svm_prob = predict(svm_fit, new_data = test_baked, type = "prob") %>% 
      pull (.pred_1.01605975626787)
    )

#investigating metrics
#convert log_class numeric
test_results$log_class <- as.numeric(test_results$log_class)

metrics(test_results, truth = diagnosis, estimate = log_class) %>% 
  knitr::kable()

test_results %>%
  select(diagnosis, log_class, log_prob) %>%
  knitr::kable()


#Plotting area-under-the-curve (ROC-curve)
  #change diagnosis to factor first
test_results$diagnosis <- as.factor(test_results$diagnosis)

test_results %>%
  roc_curve(truth = diagnosis, log_prob) %>%
  autoplot()

```


